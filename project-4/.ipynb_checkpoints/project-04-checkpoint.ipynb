{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Web Scraping Job Postings\n",
    "\n",
    "## Business Case Overview\n",
    "\n",
    "You're working as a data scientist for a contracting firm that's rapidly expanding. Now that they have their most valuable employee (you!), they need to leverage data to win more contracts. Your firm offers technology and scientific solutions and wants to be competitive in the hiring market. Your principal has two main objectives:\n",
    "\n",
    "   1. Determine the industry factors that are most important in predicting the salary amounts for these data.\n",
    "   2. Determine the factors that distinguish job categories and titles from each other. For example, can required skills accurately predict job title?\n",
    "\n",
    "To limit the scope, your principal has suggested that you *focus on data-related job postings*, e.g. data scientist, data analyst, research scientist, business intelligence, and any others you might think of. You may also want to decrease the scope by *limiting your search to a single region.*\n",
    "\n",
    "Hint: Aggregators like [Indeed.com](https://www.indeed.com) regularly pool job postings from a variety of markets and industries. \n",
    "\n",
    "**Goal:** Scrape your own data from a job aggregation tool like Indeed.com in order to collect the data to best answer these two questions.\n",
    "\n",
    "---\n",
    "\n",
    "## Directions\n",
    "\n",
    "In this project you will be leveraging a variety of skills. The first will be to use the web-scraping and/or API techniques you've learned to collect data on data jobs from Indeed.com or another aggregator. Once you have collected and cleaned the data, you will use it to answer the two questions described above.\n",
    "\n",
    "### QUESTION 1: Factors that impact salary\n",
    "\n",
    "To predict salary you will be building either a classification or regression model, using features like the location, title, and summary of the job. If framing this as a regression problem, you will be estimating the listed salary amounts. You may instead choose to frame this as a classification problem, in which case you will create labels from these salaries (high vs. low salary, for example) according to thresholds (such as median salary).\n",
    "\n",
    "You have learned a variety of new skills and models that may be useful for this problem:\n",
    "- NLP\n",
    "- Unsupervised learning and dimensionality reduction techniques (PCA, clustering)\n",
    "- Ensemble methods and decision tree models\n",
    "- SVM models\n",
    "\n",
    "Whatever you decide to use, the most important thing is to justify your choices and interpret your results. *Communication of your process is key.* Note that most listings **DO NOT** come with salary information. You'll need to able to extrapolate or predict the expected salaries for these listings.\n",
    "\n",
    "### QUESTION 2: Factors that distinguish job category\n",
    "\n",
    "Using the job postings you scraped for part 1 (or potentially new job postings from a second round of scraping), identify features in the data related to job postings that can distinguish job titles from each other. There are a variety of interesting ways you can frame the target variable, for example:\n",
    "- What components of a job posting distinguish data scientists from other data jobs?\n",
    "- What features are important for distinguishing junior vs. senior positions?\n",
    "- Do the requirements for titles vary significantly with industry (e.g. healthcare vs. government)?\n",
    "\n",
    "You may end up making multiple classification models to tackle different questions. Be sure to clearly explain your hypotheses and framing, any feature engineering, and what your target variables are. The type of classification model you choose is up to you. Be sure to interpret your results and evaluate your models' performance.\n",
    "\n",
    "\n",
    "### BONUS PROBLEM\n",
    "\n",
    "Your boss would rather tell a client incorrectly that they would get a lower salary job than tell a client incorrectly that they would get a high salary job. Adjust one of your models to ease his mind, and explain what it is doing and any tradeoffs. Plot the ROC curve.\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements\n",
    "\n",
    "1. Scrape and prepare your own data.\n",
    "\n",
    "2. **Create and compare at least two models for each section**. One of the two models should be a decision tree or ensemble model. The other can be a classifier or regression of your choosing (e.g. Ridge, logistic regression, KNN, SVM, etc).\n",
    "   - Section 1: Job Salary Trends\n",
    "   - Section 2: Job Category Factors\n",
    "\n",
    "3. Prepare a polished Jupyter Notebook with your analysis for a peer audience of data scientists. \n",
    "   - Make sure to clearly describe and label each section.\n",
    "   - Comment on your code so that others could, in theory, replicate your work.\n",
    "\n",
    "4. A brief writeup in an executive summary, written for a non-technical audience.\n",
    "   - Writeups should be at least 500-1000 words, defining any technical terms, explaining your approach, as well as any risks and limitations.\n",
    "\n",
    "#### BONUS\n",
    "\n",
    "5. Answer the salary discussion by using your model to explain the tradeoffs between detecting high vs low salary positions.\n",
    "\n",
    "6. Convert your executive summary into a public blog post of at least 500 words, in which you document your approach in a tutorial for other aspiring data scientists. Link to this in your notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## Suggestions for Getting Started\n",
    "\n",
    "1. Collect data from [Indeed.com](www.indeed.com) (or another aggregator) on data-related jobs to use in predicting salary trends for your analysis.\n",
    "  - Select and parse data from *at least 1000 postings* for jobs, potentially from multiple location searches.\n",
    "2. Find out what factors most directly impact salaries (e.g. title, location, department, etc).\n",
    "  - Test, validate, and describe your models. What factors predict salary category? How do your models perform?\n",
    "3. Discover which features have the greatest importance when determining a low vs. high paying job.\n",
    "  - Your Boss is interested in what overall features hold the greatest significance.\n",
    "  - HR is interested in which SKILLS and KEY WORDS hold the greatest significance.   \n",
    "4. Author an executive summary that details the highlights of your analysis for a non-technical audience.\n",
    "5. If tackling the bonus question, try framing the salary problem as a classification problem detecting low vs. high salary positions.\n",
    "\n",
    "---\n",
    "\n",
    "## Useful Resources\n",
    "\n",
    "- Scraping is one of the most fun, useful and interesting skills out there. Donâ€™t lose out by copying someone else's code!\n",
    "- [Here is some advice on how to write for a non-technical audience](http://programmers.stackexchange.com/questions/11523/explaining-technical-things-to-non-technical-people)\n",
    "- [Documentation for BeautifulSoup can be found here](http://www.crummy.com/software/BeautifulSoup/).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data modules\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting modules\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Make sure charts appear in the notebook\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "# Stats/regressions packages\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "# Webscraping packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable viewing of all columns for DataFrames\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Setting up functions to extract information from the web scrape from Indeed.com.sg\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title(soup):\n",
    "    '''\n",
    "    Function to extract the job titles from BeautifulSoup\n",
    "    Input soup = BeautifulSoup\n",
    "    Returns a list of job titles\n",
    "    '''\n",
    "    title = []\n",
    "    for job in soup:\n",
    "        title.append(job.a.text)\n",
    "        \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location(soup):\n",
    "    '''\n",
    "    Function to extract the location from BeautifulSoup\n",
    "    Input soup = BeautifulSoup\n",
    "    Returns a list of locations\n",
    "    '''\n",
    "    locations = []\n",
    "    for job in soup:\n",
    "        try:\n",
    "            locations.append(job.find_all(\"div\",{\"class\":\"location\"})[0].text)\n",
    "        except:\n",
    "            locations.append(job.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            \n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary(soup):\n",
    "    '''\n",
    "    Function to extract the salary from BeautifulSoup\n",
    "    If salary is not found, 'No Salary Information' would be appended\n",
    "    Input soup = BeautifulSoup\n",
    "    Returns a list of salaries\n",
    "    '''\n",
    "    salary = []\n",
    "    for job in soup:\n",
    "        try:\n",
    "            salary.append(job.find_all(\"div\",{\"class\":\"salarySnippet\"})[0].text.strip())\n",
    "        except:\n",
    "            salary.append('No Salary Information')\n",
    "            \n",
    "    return salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(soup):\n",
    "    '''\n",
    "    Function to extract the summary from BeautifulSoup\n",
    "    Input soup = BeautifulSoup\n",
    "    Returns a list of summaries\n",
    "    '''\n",
    "    summary = []\n",
    "    for job in soup:\n",
    "        summary.append(job.find_all(\"div\",{\"class\":\"paddedSummary\"})[0].text.strip())\n",
    "            \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postdate(soup):\n",
    "    '''\n",
    "    Function to extract the salary from BeautifulSoup\n",
    "    If salary is not found, 'No Post Date' would be appended\n",
    "    Input soup = BeautifulSoup\n",
    "    Returns a list of post dates\n",
    "    '''\n",
    "    date = []\n",
    "    for job in soup:\n",
    "        try:\n",
    "            date.append(job.find_all(\"span\",{\"class\":\"date\"})[0].text)\n",
    "        except:\n",
    "            date.append('No Post Date')\n",
    "            \n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty DataFrame to store the webscraped information\n",
    "results = pd.DataFrame(columns=['Title', 'Location', 'Salary', 'Summary', 'Post_Date'])\n",
    "roles = ['data+science', 'data+scientist', 'data+analyst', 'business+intelligence',\n",
    "         'machine+learning', 'data+engineer']\n",
    "\n",
    "for role in roles:\n",
    "    for n in range(10,110,10):\n",
    "        # Target web page\n",
    "        url = \"https://www.indeed.com.sg/jobs?q={}&l=singapore&start={}\".format(role, n)\n",
    "\n",
    "        # Establishing the connection to the web page:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Ensuring that the html response code is OK\n",
    "        if response.status_code != 200:\n",
    "            print('Error Status Code:', response.status_code)\n",
    "            pass\n",
    "        else:\n",
    "            # Setting up the html into BeautifulSoup\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "            element = soup.find_all(\"div\",{\"class\":\"jobsearch-SerpJobCard row result\"})\n",
    "\n",
    "            # Extracting the Title, Location, Salary, Summary & Post Date information info a temp DataFrame\n",
    "            df = pd.DataFrame(columns=['Title', 'Location', 'Salary', 'Summary', 'Post_Date'])\n",
    "            df['Title'] = title(element)\n",
    "            df['Location'] = location(element)\n",
    "            df['Salary'] = salary(element)\n",
    "            df['Summary'] = summary(element)\n",
    "            df['Post_Date'] = postdate(element)\n",
    "\n",
    "            # Appending the temp DataFrame into the results\n",
    "            results = pd.concat([results, df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771, 5)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 5)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.drop_duplicates(keep='first').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 5)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['Salary'] != 'No Salary Information'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Data from Indeed.com.sg is not clean and we are unable to scrape enough data for the project due to lack of salary information\n",
    "\n",
    "Moving on to webscrape from mycareersfuture.sg using selenium\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Selenium to extract the href of the various jobs in www.mycareersfuture.sg\n",
    "\n",
    "# Setting up Selenium driver\n",
    "chromedriver = \"/Users/darren/desktop/General_Assembly/classes/week-06/labs/python-webscraping_opentable-lab-master/chromedriver/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(executable_path=chromedriver)\n",
    "\n",
    "# List of job searches and pages\n",
    "searches = ['business%20analyst','big%20data','data%20scientist','data%20analyst',\n",
    "            'deep%20learning','data%20engineer','data%20architect','artificial%20intelligence',\n",
    "            'machine%20learning','business%20intelligence','business%20data']\n",
    "pages = range(100)\n",
    "\n",
    "links = []\n",
    "\n",
    "# Looping through the pages\n",
    "for s in searches:\n",
    "    for p in pages:\n",
    "        driver.get(\"https://www.mycareersfuture.sg/search?search={}&sortBy=new_posting_date&page={}\".format(s,p))\n",
    "        sleep(5)\n",
    "        \n",
    "        # Grab the page source.\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        elements = soup.find_all(\"a\", {\"class\":\"bg-white mb3 w-100 dib v-top pa3 no-underline flex-ns flex-wrap JobCard__card___22xP3\"})\n",
    "        \n",
    "        for element in elements:\n",
    "            try:\n",
    "                links.append(element.get('href'))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "# Close browser\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Selenium to extract the relevant data from the various links that were previously extracted\n",
    "\n",
    "# Creating a DataFrame to store the information scraped\n",
    "data = pd.DataFrame(columns=['Title', 'Company', 'Location', 'Salary from', 'Salary to', 'Salary Type', 'Employment Type', 'Seniority', 'Summary'])\n",
    "\n",
    "# Setting up Selenium driver\n",
    "chromedriver = \"/Users/darren/desktop/General_Assembly/classes/week-06/labs/python-webscraping_opentable-lab-master/chromedriver/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(executable_path=chromedriver)\n",
    "\n",
    "# Extracting the relevant data and appending to DataFrame\n",
    "for link in links:\n",
    "    try:\n",
    "        driver.get(\"https://www.mycareersfuture.sg{}\".format(link))\n",
    "        sleep(5)                  \n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "        try:\n",
    "            title = soup.find_all(\"div\", {\"class\":\"jobInfo w-100 dib v-top relative\"})[0].h1.text\n",
    "        except:\n",
    "            title = None\n",
    "        try:\n",
    "            company = soup.find_all(\"div\", {\"class\":\"jobInfo w-100 dib v-top relative\"})[0].p.text\n",
    "        except:\n",
    "            company = None\n",
    "        try:\n",
    "            location = soup.find_all(\"div\", {\"class\":\"jobInfo w-100 dib v-top relative\"})[0].find(id=\"job_info\").p.text\n",
    "        except:\n",
    "            location = None\n",
    "        try:\n",
    "            salary_from = soup.find_all(\"div\", {\"class\":\"lh-solid\"})[0].find_all(\"span\",{\"class\":\"dib\"})[0].text\n",
    "        except:\n",
    "            salary_from = None\n",
    "        try:\n",
    "            salary_to = soup.find_all(\"div\", {\"class\":\"lh-solid\"})[0].find_all(\"span\",{\"class\":\"dib\"})[1].text[3:]\n",
    "        except:\n",
    "            salary_to = None\n",
    "        try:\n",
    "            salary_type = soup.find_all(\"div\", {\"class\":\"salary tr-l\"})[0].find_all(\"span\",{\"class\":\"salary_type\"})[0].text\n",
    "        except:\n",
    "            salary_type = None\n",
    "        try:\n",
    "            employment = soup.find_all(\"div\", {\"class\":\"jobInfo w-100 dib v-top relative\"})[0].find(id=\"employment_type\").text\n",
    "        except:\n",
    "            employment = None\n",
    "        try:\n",
    "            seniority = soup.find_all(\"div\", {\"class\":\"jobInfo w-100 dib v-top relative\"})[0].find(id=\"seniority\").text\n",
    "        except:\n",
    "            seniority = None\n",
    "        try:\n",
    "            summary = soup.find(id=\"description-content\").text\n",
    "        except:\n",
    "            summary = None\n",
    "\n",
    "        data = data.append({\n",
    "            'Title':title,\n",
    "            'Company':company,\n",
    "            'Location':location,\n",
    "            'Salary from':salary_from,\n",
    "            'Salary to':salary_to,\n",
    "            'Salary Type': salary_type,\n",
    "            'Employment Type':employment,\n",
    "            'Seniority':seniority,\n",
    "            'Summary':summary\n",
    "        }, ignore_index=True) \n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "driver.close()                           \n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary from</th>\n",
       "      <th>Salary to</th>\n",
       "      <th>Employment Type</th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solution Architect, Warehouse Management System</td>\n",
       "      <td>DFS VENTURE SINGAPORE (PTE) LIMITED</td>\n",
       "      <td>SINGAPORE LAND TOWER, 50 RAFFLES PLACE 048623</td>\n",
       "      <td>$11,000</td>\n",
       "      <td>to$12,000</td>\n",
       "      <td>Permanent, Full Time</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Job Description: We are looking for a strong c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analyst Consultant</td>\n",
       "      <td>INFOSYS CONSULTING PTE. LTD.</td>\n",
       "      <td>SUNTEC TOWER TWO, 9 TEMASEK BOULEVARD 038989</td>\n",
       "      <td>$5,500</td>\n",
       "      <td>to$10,000</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Professional, Non-executive</td>\n",
       "      <td>Responsibility Support Analyst for Order &amp; Exe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Business Analyst</td>\n",
       "      <td>THE BOSTON SOFTWARE SOLUTIONS INTERNATIONAL PT...</td>\n",
       "      <td>HUDSON TECHNOCENTRE, 16 NEW INDUSTRIAL ROAD 53...</td>\n",
       "      <td>$7,000</td>\n",
       "      <td>to$8,200</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>We are looking for Senior Business AnalystÂ  o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TechnicalÂ Business AnalystÂ (Digital / Internet...</td>\n",
       "      <td>OPTIMUM SOLUTIONS (SINGAPORE) PTE LTD</td>\n",
       "      <td>PLAZA 8 @ CBP, 1 CHANGI BUSINESS PARK CRESCENT...</td>\n",
       "      <td>$5,500</td>\n",
       "      <td>to$8,000</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Senior Management, Manager</td>\n",
       "      <td>Optimum Solutions (Company Registration Number...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IT Business Analyst</td>\n",
       "      <td>THATZ INTERNATIONAL PTE LTD</td>\n",
       "      <td>THE ADELPHI, 1 COLEMAN STREET 179803</td>\n",
       "      <td>$3,500</td>\n",
       "      <td>to$4,500</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Executive</td>\n",
       "      <td>Works with Subject Matter Experts &amp; Applicati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0    Solution Architect, Warehouse Management System   \n",
       "1                        Business Analyst Consultant   \n",
       "2                            Senior Business Analyst   \n",
       "3  TechnicalÂ Business AnalystÂ (Digital / Internet...   \n",
       "4                                IT Business Analyst   \n",
       "\n",
       "                                             Company  \\\n",
       "0                DFS VENTURE SINGAPORE (PTE) LIMITED   \n",
       "1                       INFOSYS CONSULTING PTE. LTD.   \n",
       "2  THE BOSTON SOFTWARE SOLUTIONS INTERNATIONAL PT...   \n",
       "3              OPTIMUM SOLUTIONS (SINGAPORE) PTE LTD   \n",
       "4                        THATZ INTERNATIONAL PTE LTD   \n",
       "\n",
       "                                            Location Salary from  Salary to  \\\n",
       "0      SINGAPORE LAND TOWER, 50 RAFFLES PLACE 048623     $11,000  to$12,000   \n",
       "1       SUNTEC TOWER TWO, 9 TEMASEK BOULEVARD 038989      $5,500  to$10,000   \n",
       "2  HUDSON TECHNOCENTRE, 16 NEW INDUSTRIAL ROAD 53...      $7,000   to$8,200   \n",
       "3  PLAZA 8 @ CBP, 1 CHANGI BUSINESS PARK CRESCENT...      $5,500   to$8,000   \n",
       "4               THE ADELPHI, 1 COLEMAN STREET 179803      $3,500   to$4,500   \n",
       "\n",
       "        Employment Type                    Seniority  \\\n",
       "0  Permanent, Full Time                      Manager   \n",
       "1             Full Time  Professional, Non-executive   \n",
       "2              Contract             Senior Executive   \n",
       "3              Contract   Senior Management, Manager   \n",
       "4             Full Time                    Executive   \n",
       "\n",
       "                                             Summary  \n",
       "0  Job Description: We are looking for a strong c...  \n",
       "1  Responsibility Support Analyst for Order & Exe...  \n",
       "2  We are looking for Senior Business AnalystÂ  o ...  \n",
       "3  Optimum Solutions (Company Registration Number...  \n",
       "4   Works with Subject Matter Experts & Applicati...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('links', 'wb') as f:\n",
    "    pickle.dump(links, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('links', 'rb') as f:\n",
    "    links = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1363"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1363, 8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1255, 8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Salary from'] != 'No Salary Info'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1355, 8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Company'] != 'No Company Info'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1363, 8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Title'] != 'No Title Info'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('webscrapedata`.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(927, 8)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(keep='first').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
